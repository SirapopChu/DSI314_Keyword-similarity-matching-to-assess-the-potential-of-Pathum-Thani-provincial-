{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbmqZYJpswow",
        "outputId": "34fc03f4-9118-4e0d-9445-715ab8de73f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.10/dist-packages (5.0.4)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install pythainlp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Top 10 by TF-IDF Score ranking"
      ],
      "metadata": {
        "id": "788drddWTKY9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-HyS8AlogYO",
        "outputId": "7518ba11-0d06-4029-c838-173ba2127246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data saved to 'projects_61_65_with_strategy.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pythainlp.util import normalize\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Load your CSV file\n",
        "projects_df = pd.read_csv('/content/pasi_61_65_dataset.csv')  # Replace 'projects.csv' with your actual file name\n",
        "\n",
        "# Sample keywords DataFrame with multiple keywords per strategy label\n",
        "keywords_df = pd.DataFrame({\n",
        "    'strategy_label': [\n",
        "        'ประเด็นการพัฒนาที่ 1 : พัฒนาสภาพแวดล้อมเมืองให้น่าอยู่ เอื้อต่อการขยายตัวทางเศรษฐกิจและสังคม',\n",
        "        'ประเด็นการพัฒนาที่ 2 : ยกระดับการผลิตอาหาร สินค้าเกษตร อุตสาหกรรม ให้มีคุณภาพและได้มาตรฐาน สู่ตลาดโลก',\n",
        "        'ประเด็นการพัฒนาที่ 3 : พัฒนามาตรฐานการท่องเที่ยว เชื่อมโยงธุรกิจและบริการด้านการท่องเที่ยว',\n",
        "        'ประเด็นการพัฒนาที่ 4 : พัฒนาและเสริมสร้างศักยภาพคนและชุมชนให้มีคุณภาพเพื่อรองรับการเปลี่ยนแปลงโครงสร้างประชากรและสังคม'\n",
        "    ],\n",
        "    'keywords': [\n",
        "        ['เขื่อน','ฝาย','ลำน้ำ','ลำห้วย','ห้วย',\n",
        "         'ตลิ่ง',\n",
        "         'ภูมิทัศน์',\n",
        "         'น้ำ',\n",
        "         'ทางหลวง','ช่องจราจร'\n",
        "         'แม่น้ำ','คลอง',\n",
        "         'ชุมชน','หมู่บ้าน'\n",
        "         'ขยะ','ขยะมูลฝอย'],\n",
        "\n",
        "        ['สินค้า','ตลาด',\n",
        "         'เกษตร','เกษตรกร',\n",
        "         'อาหาร','เนื้อ','ปศุสัตว์',\n",
        "         'ผลิตภัณฑ์',\n",
        "         'อุตสาหกรรม',\n",
        "         'สากล'],\n",
        "\n",
        "        ['วิถี',\n",
        "         'ชุมชน', 'หมู่บ้าน',\n",
        "         'วัฒนธรรม',\n",
        "         'ประเพณี',\n",
        "         'แหล่งท่องเที่ยว','สถานที่สำคัญ','สถานที่ท่องเที่ยว','นักท่องเที่ยว'\n",
        "         'แรลลี่',\n",
        "         'ป้าย','แผ่นป้าย'\n",
        "         'สื่อ'],\n",
        "\n",
        "        ['คอนกรีตเสริมเหล็ก','คอนกรีต'\n",
        "         'ถนน','ซอย','สะพาน'\n",
        "         'ท่อ',\n",
        "         'แรงดัน',\n",
        "         'บ่อพัก',\n",
        "         'บ่อ',\n",
        "         'ผิวจราจร',\n",
        "         'แรงงาน',\n",
        "         'ผู้สูงอายุ',\n",
        "         ]\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Normalize and tokenize Thai text\n",
        "def process_text(text):\n",
        "    normalized_text = normalize(str(text))  # Ensure text is string\n",
        "    return word_tokenize(normalized_text, keep_whitespace=False)\n",
        "\n",
        "# Match keywords and assign only the first matching strategy label\n",
        "def assign_strategy(project_name_tokens, keywords_df):\n",
        "    for _, row in keywords_df.iterrows():\n",
        "        strategy_label = row['strategy_label']\n",
        "        keywords = row['keywords']\n",
        "        # Tokenize and normalize all keywords\n",
        "        keyword_tokens_list = [process_text(keyword) for keyword in keywords]\n",
        "        # Flatten the tokenized keywords into a single list\n",
        "        keyword_tokens = [token for tokens in keyword_tokens_list for token in tokens]\n",
        "        # Check if any keyword matches the project name tokens\n",
        "        if any(token in project_name_tokens for token in keyword_tokens):\n",
        "            return strategy_label  # Return the first matching strategy label\n",
        "    return None  # No matching label\n",
        "\n",
        "# Process the 'project_name' column in your CSV\n",
        "projects_df['project_name_tokens'] = projects_df['project_name'].apply(process_text)\n",
        "projects_df['strategy_label'] = projects_df['project_name_tokens'].apply(\n",
        "    lambda tokens: assign_strategy(tokens, keywords_df)\n",
        ")\n",
        "\n",
        "# Drop intermediate tokens column if not needed\n",
        "projects_df.drop(columns=['project_name_tokens'], inplace=True)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV\n",
        "projects_df.to_csv('projects_61_65_with_strategy.csv', index=False)\n",
        "\n",
        "print(\"Processed data saved to 'projects_61_65_with_strategy.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use LLm intersections word"
      ],
      "metadata": {
        "id": "rBlir2s91fuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pythainlp.util import normalize\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Load your CSV file\n",
        "projects_df = pd.read_csv('/content/pasi_61_65_dataset.csv')  # Replace 'projects.csv' with your actual file name\n",
        "\n",
        "# Sample keywords DataFrame with multiple keywords per strategy label\n",
        "keywords_df = pd.DataFrame({\n",
        "    'strategy_label': [\n",
        "        'ประเด็นการพัฒนาที่ 1 : พัฒนาสภาพแวดล้อมเมืองให้น่าอยู่ เอื้อต่อการขยายตัวทางเศรษฐกิจและสังคม',\n",
        "        'ประเด็นการพัฒนาที่ 2 : ยกระดับการผลิตอาหาร สินค้าเกษตร อุตสาหกรรม ให้มีคุณภาพและได้มาตรฐาน สู่ตลาดโลก',\n",
        "        'ประเด็นการพัฒนาที่ 3 : พัฒนามาตรฐานการท่องเที่ยว เชื่อมโยงธุรกิจและบริการด้านการท่องเที่ยว',\n",
        "        'ประเด็นการพัฒนาที่ 4 : พัฒนาและเสริมสร้างศักยภาพคนและชุมชนให้มีคุณภาพเพื่อรองรับการเปลี่ยนแปลงโครงสร้างประชากรและสังคม'\n",
        "    ],\n",
        "\n",
        "    'keywords': [\n",
        "        [\"สิ่งแวดล้อม\",\"ทรัพยากรธรรมชาติ\",\"ระบบนิเวศ\",\"การอนุรักษ์\",\"การพัฒนา\",\n",
        "         \"ชุมชน\", \"หมู่บ้าน\",\"ชนบท\",\"ที่อยู่อาศัย\",\n",
        "         \"ทางหลวง\",\"ช่องจราจร\",\n",
        "         \"น้ำ\",\"แหล่งน้ำ\",\n",
        "         \"ไฟฟ้า\",\"กระแสไฟฟ้า\",\"พลังงานไฟฟ้า\",\n",
        "         \"ขยะมูลฝอย\",\"ขยะ\",\"น้ำเสีย\",\"สิ่งปฏิกูล\",\"มูลฝอย\"\n",
        "        ],\n",
        "\n",
        "        [\"สินค้า\",\"ตลาด\",\"ผู้บริโภค\",\n",
        "         \"อาหาร\",\"บริโภค\",\n",
        "         \"เกษตร\",\"การเกษตร\",\"เกษตรกรรม\",\"เกษตรกร\",\n",
        "         \"ผลิตภัณฑ์\",\"วัตถุดิบ\",\"อุตสาหกรรม\",\n",
        "         \"ฟาร์ม\",\"ปศุสัตว์\",\n",
        "         \"มาตรฐานสากล\",\"มาตรฐาน\"\n",
        "        ],\n",
        "\n",
        "        [\"ผลิตภัณฑ์\",\n",
        "         \"แหล่งท่องเที่ยว\",\"สถานที่ท่องเที่ยว\",\"นักท่องเที่ยว\",\"สถานที่สำคัญ\",\n",
        "         \"อาหาร\",\"บริโภค\",\n",
        "         \"เทศกาล\",\"งานเทศกาล\",\n",
        "         \"วัฒนธรรม\",\"ภูมิปัญญา\",\"ศิลปวัฒนธรรม\",\"วัฒนธรรมประเพณี\",\n",
        "         \"ประเพณี\",\"พิธีกรรม\",\"ขนบธรรมเนียม\",\"ธรรมเนียม\",\"ขนบธรรมเนียมประเพณี\",\n",
        "         \"ชุมชน\",\"หมู่บ้าน\",\"ชนบท\",\"ที่อยู่อาศัย\",\n",
        "         \"ภูมิทัศน์\",\"ทิวทัศน์\",\n",
        "         \"วิถี\"\n",
        "        ],\n",
        "\n",
        "        [\"ประชาชน\",\"พลเมือง\",\n",
        "         \"คุณภาพชีวิต\",\"เสริมสร้าง\",\"การพัฒนา\",\"การส่งเสริม\",\n",
        "         \"เยาวชน\",\"ยุวชน\",\"เด็ก\",\n",
        "         \"อาชีพ\",\n",
        "         \"ชุมชน\",\"หมู่บ้าน\",\"ชนบท\",\"ที่อยู่อาศัย\",\n",
        "         \"อาสาสมัคร\",\"เจ้าหน้าที่\",\"อาสา\",\n",
        "         \"ภูมิปัญญาท้องถิ่น\",\"ภูมิปัญญา\",\"ศิลปวัฒนธรรม\",\"วัฒนธรรมประเพณี\",\n",
        "         \"ผู้สูงอายุ\",\n",
        "         \"ทักษะ\",\"ความสามารถ\",\"ประสบการณ์\",\"ความชำนาญ\"\n",
        "        ]\n",
        "\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Normalize and tokenize Thai text\n",
        "def process_text(text):\n",
        "    normalized_text = normalize(str(text))  # Ensure text is string\n",
        "    return word_tokenize(normalized_text, keep_whitespace=False)\n",
        "\n",
        "# Match keywords and assign only the first matching strategy label\n",
        "def assign_strategy(project_name_tokens, keywords_df):\n",
        "    for _, row in keywords_df.iterrows():\n",
        "        strategy_label = row['strategy_label']\n",
        "        keywords = row['keywords']\n",
        "        # Tokenize and normalize all keywords\n",
        "        keyword_tokens_list = [process_text(keyword) for keyword in keywords]\n",
        "        # Flatten the tokenized keywords into a single list\n",
        "        keyword_tokens = [token for tokens in keyword_tokens_list for token in tokens]\n",
        "        # Check if any keyword matches the project name tokens\n",
        "        if any(token in project_name_tokens for token in keyword_tokens):\n",
        "            return strategy_label  # Return the first matching strategy label\n",
        "    return None  # No matching label\n",
        "\n",
        "# Process the 'project_name' column in your CSV\n",
        "projects_df['project_name_tokens'] = projects_df['project_name'].apply(process_text)\n",
        "projects_df['strategy_label'] = projects_df['project_name_tokens'].apply(\n",
        "    lambda tokens: assign_strategy(tokens, keywords_df)\n",
        ")\n",
        "\n",
        "# Drop intermediate tokens column if not needed\n",
        "projects_df.drop(columns=['project_name_tokens'], inplace=True)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV\n",
        "projects_df.to_csv('projects_61_65_LLM_with_strategy.csv', index=False)\n",
        "\n",
        "print(\"Processed data saved to 'projects_61_65_LLM_with_strategy.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNFH4CHbX_bZ",
        "outputId": "cb13eb95-99a4-4555-8433-828c37e84689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data saved to 'projects_61_65_LLM_with_strategy.csv'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}